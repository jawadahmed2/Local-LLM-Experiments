{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZWXtHsfR1CRx"
      },
      "outputs": [],
      "source": [
        "!pip -qqq install ollama==0.1.9 --progress-bar off\n",
        "!pip -qqq install pydantic==2.7.4 --progress-bar off\n",
        "!pip -qqq install langchain-core==0.2.7 --progress-bar off\n",
        "!pip -qqq install openai==1.35.3 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DaIV6agC2zYt"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from enum import Enum\n",
        "from typing import Generic, Type, TypeVar\n",
        "\n",
        "from openai import OpenAI\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local Ollama client\n",
        "client = OpenAI(\n",
        "    base_url = 'http://localhost:11434/v1',\n",
        "    api_key='ollama',\n",
        ")\n",
        "MODEL = 'llama3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gcGRpt7O2-5m"
      },
      "outputs": [],
      "source": [
        "tweet = \"\"\"\n",
        "How do you choose which LLM to use?\n",
        "\n",
        "A vibe check ain't going to cut it.\n",
        "\n",
        "I'm trying DeepEval (@jeffr_yyy)\n",
        "\n",
        "- Wide range of metrics: Relevancy, Hallucination & more\n",
        "- Bulk & real-time evaluation\n",
        "- CI/CD integration\n",
        "- Benchmarking on popular datasets\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FAOrKrTX9qi4"
      },
      "outputs": [],
      "source": [
        "class ResponseFormat(Enum):\n",
        "    JSON = \"json\"\n",
        "    TEXT = \"text\"\n",
        "\n",
        "\n",
        "def predict(\n",
        "    prompt: str,\n",
        "    system_prompt: str = None,\n",
        "    response_format: ResponseFormat = ResponseFormat.TEXT,\n",
        "    model: str = MODEL,\n",
        "    client: OpenAI = client,\n",
        "):\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "    if system_prompt:\n",
        "        messages.insert(\n",
        "            0,\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt,\n",
        "            },\n",
        "        )\n",
        "    try:\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=model,\n",
        "            temperature=0.00001,\n",
        "            response_format={\n",
        "                \"type\": \"json_object\"\n",
        "                if response_format == ResponseFormat.JSON\n",
        "                else \"text\"\n",
        "            },\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(\"There is error\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6OoU_-peTnk"
      },
      "source": [
        "## JSON Output Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbGU_Fp5ms_o",
        "outputId": "2302d7e0-9715-410e-b357-e21da0e7517c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You're evaluating writing style in text.\n",
            "Your evalutions must always be in JSON format. Here is an example JSON response:\n",
            "\n",
            "```\n",
            "{\n",
            "  'readability': 4,\n",
            "  'conciseness': 2\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"\"\"\n",
        "You're evaluating writing style in text.\n",
        "Your evalutions must always be in JSON format. Here is an example JSON response:\n",
        "\n",
        "```\n",
        "{\n",
        "  'readability': 4,\n",
        "  'conciseness': 2\n",
        "}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "print(system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtT6HRlXmp2f",
        "outputId": "d9591c47-24a0-4709-fe9e-a492b5819526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluate the text:\n",
            "\n",
            "```\n",
            "\n",
            "How do you choose which LLM to use?\n",
            "\n",
            "A vibe check ain't going to cut it.\n",
            "\n",
            "I'm trying DeepEval (@jeffr_yyy)\n",
            "\n",
            "- Wide range of metrics: Relevancy, Hallucination & more\n",
            "- Bulk & real-time evaluation\n",
            "- CI/CD integration\n",
            "- Benchmarking on popular datasets\n",
            "\n",
            "```\n",
            "\n",
            "You're evaluating the readability and conciseness with values from 0 (extremely bad) to 10 (extremely good)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Evaluate the text:\n",
        "\n",
        "```\n",
        "{tweet}\n",
        "```\n",
        "\n",
        "You're evaluating the readability and conciseness with values from 0 (extremely bad) to 10 (extremely good)\n",
        "\"\"\"\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_IVKObyGn7pp"
      },
      "outputs": [],
      "source": [
        "response = predict(prompt, system_prompt, response_format=ResponseFormat.JSON)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qugrxq7zosln",
        "outputId": "8875a6c7-04d7-4b0c-93ad-09d78c50cfd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \"readability\": 8, \"conciseness\": 9 }\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn8JyJmFeV8D"
      },
      "source": [
        "## No JSON Output Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NE8b7_AFvXSi"
      },
      "outputs": [],
      "source": [
        "class WritingScore(BaseModel):\n",
        "    readability: int\n",
        "    conciseness: int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsf8Ub_qvYcv",
        "outputId": "3a76acf5-db1e-4813-d680-e9194de6f8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"properties\": {\n",
            "    \"readability\": {\n",
            "      \"title\": \"Readability\",\n",
            "      \"type\": \"integer\"\n",
            "    },\n",
            "    \"conciseness\": {\n",
            "      \"title\": \"Conciseness\",\n",
            "      \"type\": \"integer\"\n",
            "    }\n",
            "  },\n",
            "  \"required\": [\n",
            "    \"readability\",\n",
            "    \"conciseness\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "schema = {k: v for k, v in WritingScore.schema().items()}\n",
        "schema = {\"properties\": schema[\"properties\"], \"required\": schema[\"required\"]}\n",
        "print(json.dumps(schema, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "68jzcw8fvbGO"
      },
      "outputs": [],
      "source": [
        "OUTPUT_FORMAT_INSTRUCTIONS = \"\"\"The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
        "\n",
        "As an example, for the schema {{\"properties\": {{\"foo\": {{\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {{\"type\": \"string\"}}}}}}, \"required\": [\"foo\"]}}\n",
        "the object {{\"foo\": [\"bar\", \"baz\"]}} is a well-formatted instance of the schema. The object {{\"properties\": {{\"foo\": [\"bar\", \"baz\"]}}}} is not well-formatted.\n",
        "\n",
        "Here is the output schema:\n",
        "\n",
        "```\n",
        "{schema}\n",
        "```\n",
        "\n",
        "Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhW-ohIJvcWo",
        "outputId": "7318a3b3-082a-41d5-ed43-0cffbb727120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"properties\": {\n",
            "    \"readability\": {\n",
            "      \"title\": \"Readability\",\n",
            "      \"type\": \"integer\"\n",
            "    },\n",
            "    \"conciseness\": {\n",
            "      \"title\": \"Conciseness\",\n",
            "      \"type\": \"integer\"\n",
            "    }\n",
            "  },\n",
            "  \"required\": [\n",
            "    \"readability\",\n",
            "    \"conciseness\"\n",
            "  ]\n",
            "}\n",
            "```\n",
            "\n",
            "Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).\n"
          ]
        }
      ],
      "source": [
        "json_instruction = OUTPUT_FORMAT_INSTRUCTIONS.format(\n",
        "    schema=json.dumps(schema, indent=2)\n",
        ")\n",
        "print(json_instruction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAhiXP5-vmaw",
        "outputId": "d135d4d0-bd5b-41fc-deb8-40054fc7233b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluate the writing style from the text:\n",
            "\n",
            "```\n",
            "\n",
            "How do you choose which LLM to use?\n",
            "\n",
            "A vibe check ain't going to cut it.\n",
            "\n",
            "I'm trying DeepEval (@jeffr_yyy)\n",
            "\n",
            "- Wide range of metrics: Relevancy, Hallucination & more\n",
            "- Bulk & real-time evaluation\n",
            "- CI/CD integration\n",
            "- Benchmarking on popular datasets\n",
            "\n",
            "```\n",
            "\n",
            "Evaluate the readability and conciseness with values from 0 (extremely bad) to 10 (extremely good).\n",
            "Just give the output values for readability and conciseness in JSON format. Do not include any other information.\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"properties\": {\n",
            "    \"readability\": {\n",
            "      \"title\": \"Readability\",\n",
            "      \"type\": \"integer\"\n",
            "    },\n",
            "    \"conciseness\": {\n",
            "      \"title\": \"Conciseness\",\n",
            "      \"type\": \"integer\"\n",
            "    }\n",
            "  },\n",
            "  \"required\": [\n",
            "    \"readability\",\n",
            "    \"conciseness\"\n",
            "  ]\n",
            "}\n",
            "```\n",
            "\n",
            "Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Evaluate the writing style from the text:\n",
        "\n",
        "```\n",
        "{tweet}\n",
        "```\n",
        "\n",
        "Evaluate the readability and conciseness with values from 0 (extremely bad) to 10 (extremely good).\n",
        "Just give the output values for readability and conciseness in JSON format. Do not include any other information.\n",
        "\n",
        "{json_instruction}\n",
        "\"\"\"\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veYpcsEFvpbt",
        "outputId": "8dc41cf5-4312-475d-c960-5dd4623dd1fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```{\"readability\":6,\"conciseness\":8}```\n"
          ]
        }
      ],
      "source": [
        "response = predict(prompt, MODEL)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NWTNINsFRXU"
      },
      "source": [
        "## From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-kAhaLeNRbD",
        "outputId": "2c25363b-830f-42a5-f654-08df9ec23471"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WritingScore(readability=6, conciseness=8)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_json = json.loads(response.strip(\"```\"))\n",
        "WritingScore.model_validate(response_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rOwcuyScP-YQ"
      },
      "outputs": [],
      "source": [
        "TBaseModel = TypeVar(\"TBaseModel\", bound=BaseModel)\n",
        "\n",
        "\n",
        "class JsonOutputParser(Generic[TBaseModel]):\n",
        "    def __init__(self, pydantic_object: Type[TBaseModel]):\n",
        "        self.pydantic_object = pydantic_object\n",
        "\n",
        "    def parse(self, response: str):\n",
        "        response_json = json.loads(response.strip(\"```\"))\n",
        "        return self.pydantic_object.parse_obj(response_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnyYTE0mXss8",
        "outputId": "7fd45560-28b8-45f1-e721-4675b7d64808"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WritingScore(readability=6, conciseness=8)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "JsonOutputParser(pydantic_object=WritingScore).parse(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KSkb7XwOgYL"
      },
      "source": [
        "## Using LangChain Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9kVcsoQEOitm"
      },
      "outputs": [],
      "source": [
        "parser = PydanticOutputParser(pydantic_object=WritingScore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Gqy9rvvBoE",
        "outputId": "ed769c3e-ed3b-4f44-f6dd-509cd7cf97ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WritingScore(readability=6, conciseness=8)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.parse(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
